{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc95cf2b",
   "metadata": {},
   "source": [
    "# Część 1: Podstawy HTML i XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6603",
   "metadata": {},
   "source": [
    "1. Tagi, atrybuty, i elementy:\n",
    "\n",
    "* Tagi to podstawowe składniki języka HTML i XML. Są one umieszczane w nawiasach ostrokątnych, np. &lt;html>, &lt;body>,  &lt;div>.\n",
    "* Atrybuty dostarczają dodatkowych informacji o tagach. Przykład: w tagu &lt;a href=\"https://example.com\"&gt;, href jest atrybutem definiującym adres URL linku.\n",
    "* Elementy składają się z otwierającego tagu, zawartości i zamykającego tagu. Na przykład, &lt;p>To jest paragraf.&lt;/p>, &lt;a> href=hiperłącze &lt;/a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc4be8a",
   "metadata": {},
   "source": [
    "2. Nagłówki w HTML\n",
    "* Nagłówki to elementy HTML używane do organizacji i strukturyzacji treści na stronie internetowej. Są one oznaczane tagami od &lt;h1> do &lt;h6>.\n",
    "* &lt;h1> reprezentuje najważniejszy nagłówek na stronie, zwykle tytuł lub główny punkt strony, a &lt;h6> jest najmniej istotnym nagłówkiem.\n",
    "* Użycie nagłówków pomaga w tworzeniu hierarchii informacji na stronie, co jest ważne zarówno dla użytkowników, jak i dla wyszukiwarek internetowych.\n",
    "Przykład:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d158141",
   "metadata": {},
   "source": [
    "<h1>Tytuł główny strony</h1>\n",
    "<h2>Podsekcja 1</h2>\n",
    "<p>Treść podsekcji 1...</p>\n",
    "<h2>Podsekcja 2</h2>\n",
    "<p>Treść podsekcji 2...</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92a8333",
   "metadata": {},
   "source": [
    "3. HTML a XML:\n",
    "* HTML jest używany głównie do tworzenia stron internetowych i jest bardziej elastyczny co do składni.\n",
    "XML służy do przechowywania i przesyłania danych i wymaga ścisłego przestrzegania zasad dobrze sformowanego dokumentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab8a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie przykładowego pliku XML\n",
    "xml_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<library>\n",
    "    <book>\n",
    "        <title>Przygody Tomka Sawyera</title>\n",
    "        <author>Mark Twain</author>\n",
    "        <year>1876</year>\n",
    "    </book>\n",
    "    <book>\n",
    "        <title>Pan Tadeusz</title>\n",
    "        <author>Adam Mickiewicz</author>\n",
    "        <year>1834</year>\n",
    "    </book>\n",
    "</library>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093e720",
   "metadata": {},
   "source": [
    "4. Narzędzia do inspekcji strony:\n",
    "\n",
    "Narzędzia deweloperskie w przeglądarkach internetowych (takie jak Chrome, Firefox, Edge) pozwalają na oglądanie struktury HTML, stylów CSS i skryptów JavaScript strony. Można je otworzyć klikając prawym przyciskiem myszy na stronie i wybierając \"Zbadaj\" lub naciskając F12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90449daa",
   "metadata": {},
   "source": [
    "**Ćwiczenie:**\n",
    "\n",
    "Należy utworzyć bardzo prostą stronę internetową zawierającą tytuł, kilka nagłówków i paragrafów. Jeden paragraf ma zawierać hiperłącze do strony MiMUW. Utworzoną stronę proszę zapisać w pliku i podejrzeć w przeglądarce z wykorzystaniem \"Zbadaj\" (zazwyczaj F12).\n",
    "\n",
    "Ewentualnie można skorzystać z poniższej przykładowej implementacji (w zależności od znajomości HTML). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeebe715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie przykładowej strony HTML (do późniejszego przetwarzania przy użyciu BeautifulSoup)\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html> \n",
    "<html>\n",
    "<head>\n",
    "    <title>Page title - Webscraping</title>\n",
    "</head>\n",
    "<body>\n",
    "    <h1>Level 1 header</h1>\n",
    "    <h2>Level 2 header</h2>\n",
    "    <p>A paragraph.</p>\n",
    "    <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7563ca6-9e60-4e04-a575-012ea01e8304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu wpisz rozwiązanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd083725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Po zapisie strony możemy otworzyć ją (domyślnie powinna otworzyć się w przeglądarce internetowej) i obejrzeć w jaki sposób \n",
    "# wygląda i widoczna jest w trybie inspektora (F12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c16f8",
   "metadata": {},
   "source": [
    "# Część 2: Parsowanie HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe75b4",
   "metadata": {},
   "source": [
    "W tej części skupimy się na narzędziach wykorzystywanych do parsowania treści HTML. Bardzo popularnym pakietem jest Beautiful Soup. Jest to pakiet, który służy do parsowania dokumentów HTML i XML. Jest szczególnie użyteczny w web scrapingu, czyli procesie ekstrakcji danych z stron internetowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cebc84",
   "metadata": {},
   "source": [
    "Napiszmy więc kod, w którym wykorzystamy pakiet BeautifulSoup do analizy naszej strony i wyszukania w niej nagłówków, tytułów oraz paragrafów. Przekonamy się, jak łatwo można przetwarzać HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7f5c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_file_path = './my_website.html'\n",
    "\n",
    "# Wczytywanie zawartości strony HTML\n",
    "with open(html_file_path, 'r') as file:\n",
    "    html_page = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d71c800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<DOCTYPE html>\\n<html lang=\"en\">\\n<head>\\n    <title>Page title - Webscraping</title>\\n</head>\\n<body>\\n    <h1>Level 1 header</h1>\\n    <h2>Level 2 header</h2>\\n    <p>A paragraph.</p>\\n    <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\\n</body>\\n</html>\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271ab001",
   "metadata": {},
   "source": [
    "Utworzymy obiekt BeautifulSoup - jako parser wybieramy wbudowany (nie wymagający instalacji/importu dodatkowych pakietów) parser html.\n",
    "Wybór parsera zależny jest od założeń oraz wymagań projektów, jednakże dla tak małych stron html.parser jest wystarczający.\n",
    "W przypadku znacznie większych stron warto rozważyć wykorzystanie lxml, który jest szybszy (wymaga jednak instalacji dodatkowych zależności). Więcej na ten temat można poczytać w dokumentacji:\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bdd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace7a1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<doctype html=\"\">\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<title>Page title - Webscraping</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Level 1 header</h1>\n",
       "<h2>Level 2 header</h2>\n",
       "<p>A paragraph.</p>\n",
       "<p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>\n",
       "</body>\n",
       "</html>\n",
       "</doctype>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3127db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doctype html=\"\">\n",
      " <html lang=\"en\">\n",
      "  <head>\n",
      "   <title>\n",
      "    Page title - Webscraping\n",
      "   </title>\n",
      "  </head>\n",
      "  <body>\n",
      "   <h1>\n",
      "    Level 1 header\n",
      "   </h1>\n",
      "   <h2>\n",
      "    Level 2 header\n",
      "   </h2>\n",
      "   <p>\n",
      "    A paragraph.\n",
      "   </p>\n",
      "   <p>\n",
      "    Next paragraph with\n",
      "    <a href=\"https://www.mimuw.edu.pl/\">\n",
      "     links\n",
      "    </a>\n",
      "    at the end.\n",
      "   </p>\n",
      "  </body>\n",
      " </html>\n",
      "</doctype>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I bardziej czytelnie\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05244ba1",
   "metadata": {},
   "source": [
    "A więc mamy już sparsowaną treść naszej strony - możemy więc przejść do wyszukiwania na niej informacji. W naszym przypadku (choć jest ich niewiele) - możemy pobrać tytuł, nagłówki oraz paragrafy. Spróbujemy również pobrać link do strony MiMUW."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eaf87b",
   "metadata": {},
   "source": [
    "Tytuł strony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e9a59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyszukiwanie tytułu strony\n",
    "page_title = soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d259de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Page title - Webscraping</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360c88e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page title - Webscraping'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_title.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942ef099",
   "metadata": {},
   "source": [
    "Nagłówki - h1, h2. Wykorzystamy metody\n",
    "* find() - służy do wyszukiwania pierwszego wystąpienia danego tagu lub tagów spełniających określone kryteria.\n",
    "* find_all() - znajduje wszystkie tagi spełniające te kryteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560cbe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyszukiwanie wszystkich nagłówków h1 i h2\n",
    "headers_h1 = soup.find_all('h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b84b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'string'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mheaders_h1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m \u001b[38;5;66;03m# Nie działa - dlaczego? find_all zwraca listę\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/element.py:2433\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2434\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[1;32m   2435\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'string'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "headers_h1.string # Nie działa - dlaczego? find_all zwraca listę"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5952b641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Level 1 header'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_h1[0].string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e903ec",
   "metadata": {},
   "source": [
    "No ale w naszym przypadku mamy przecież 1 element h1 (h2 również), a więc w zupełności wystarczyłoby find. \"W naszym przypadku\", gdyż zazwyczaj nie znamy strony i może ona zawierać setki różnego rodzaju tagów. Bezpieczniej więc skorzystać z find_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dae25258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla porównania - find\n",
    "headers_h2 = soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8869649e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Level 2 header'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_h2.string # Tutaj już w porządku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ec50b",
   "metadata": {},
   "source": [
    "Wyszukiwanie wszystkich paragrafów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3844e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyszukiwanie wszystkich paragrafów\n",
    "paragraphs = soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b41cedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>A paragraph.</p>,\n",
       " <p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e8733d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A paragraph.', None]\n"
     ]
    }
   ],
   "source": [
    "print([p.string for p in paragraphs]) # Pod indeksem 1 mamy None, dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9742cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs[1].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30273683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Next paragraph with <a href=\"https://www.mimuw.edu.pl/\">links</a> at the end.</p>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[1] # Ponieważ w paragrafie znajduje się tag a. Ten z kolei ma atrybut href i jakąś przypisną mu wartość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f8c169f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.mimuw.edu.pl/\">links</a>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tutaj postępujemy w następujący sposób\n",
    "paragraphs[1].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61ba9e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.mimuw.edu.pl/\">links</a>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lub\n",
    "paragraphs[1].find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "289640d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.mimuw.edu.pl/\">links</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lub \n",
    "paragraphs[1].find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bd6e833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.mimuw.edu.pl/\">links</a>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lub - możliwości jest bardzo dużo\n",
    "# Select - umożliwia wyszukiwanie elementów za pomocą selektorów CSS.\n",
    "paragraphs[1].select('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71c92f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n",
      "https://www.mimuw.edu.pl/\n"
     ]
    }
   ],
   "source": [
    "# A następnie odwołujemy się do atrybutu href i mamy hiperłącze do MiMUW :)\n",
    "print(paragraphs[1].a['href'])\n",
    "print(paragraphs[1].find('a')['href'])\n",
    "print(paragraphs[1].find_all('a')[0]['href'])\n",
    "print(paragraphs[1].select('a')[0]['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42dc6b7",
   "metadata": {},
   "source": [
    "Zaprezentowanych zostanie teraz kilka innych przydatnych metod z ich wykorzystaniem - na przykładzie naszej strony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1a0907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find() - wyszukuje pierwszy paragraf\n",
    "first_paragraph = soup.find('p').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a8be6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_all() - znajduje wszystkie paragrafy\n",
    "all_paragraphs = [p.text for p in soup.find_all('p')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72a43d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select() - wybiera wszystkie linki (tagi a) w dokumencie\n",
    "all_links = soup.select('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f0aeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_one() - wybiera pierwszy tag h1\n",
    "first_h1 = soup.select_one('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89c0a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_parent() - znajduje rodzica pierwszego linku (w tym przypadku paragraf)\n",
    "parent_of_first_link = soup.find('a').find_parent().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbb35405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_next_sibling() - znajduje następujące rodzeństwo po pierwszym nagłówku h1 (w tym przypadku h2)\n",
    "next_sibling_of_h1 = soup.find('h1').find_next_sibling().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec3cbd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atrybuty - pobiera atrybut href pierwszego linku\n",
    "first_link_href = soup.find('a')['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d615f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyniki\n",
    "results = {\n",
    "    \"Pierwszy paragraf\": first_paragraph,\n",
    "    \"Wszystkie paragrafy\": all_paragraphs,\n",
    "    \"Wszystkie linki\": [link['href'] for link in all_links],\n",
    "    \"Pierwszy nagłówek h1\": first_h1,\n",
    "    \"Rodzic pierwszego linku\": parent_of_first_link,\n",
    "    \"Następne rodzeństwo po h1\": next_sibling_of_h1,\n",
    "    \"Href pierwszego linku\": first_link_href\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de752611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pierwszy paragraf': 'A paragraph.',\n",
       " 'Wszystkie paragrafy': ['A paragraph.',\n",
       "  'Next paragraph with links at the end.'],\n",
       " 'Wszystkie linki': ['https://www.mimuw.edu.pl/'],\n",
       " 'Pierwszy nagłówek h1': 'Level 1 header',\n",
       " 'Rodzic pierwszego linku': 'Next paragraph with links at the end.',\n",
       " 'Następne rodzeństwo po h1': 'Level 2 header',\n",
       " 'Href pierwszego linku': 'https://www.mimuw.edu.pl/'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51abffb",
   "metadata": {},
   "source": [
    "Select vs find\n",
    "\n",
    "* find i find_all skupiają się na atrybutach i nazwach tagów.\n",
    "* select i select_one zapewniają większą elastyczność dzięki wykorzystaniu selektorów CSS, co pozwala na bardziej złożone zapytania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91accf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = \"\"\"\n",
    "<div>\n",
    "    <p class=\"text\">Pierwszy paragraf</p>\n",
    "    <p class=\"text\">Drugi paragraf</p>\n",
    "    <p class=\"text\" id=\"special\">Trzeci paragraf</p>\n",
    "</div>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82e4aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(html_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92d2b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla tak zdefiniowanej strony mamy:\n",
    "first_paragraph = soup2.find('p')  # Znajduje pierwszy paragraf\n",
    "all_paragraphs = soup2.find_all('p')  # Znajduje wszystkie paragrafy\n",
    "special_paragraph = soup2.select_one('#special')  # Znajduje paragraf z ID 'special'\n",
    "text_paragraphs = soup2.select('p.text')  # Znajduje paragrafy z klasą 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19cbaeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>,\n",
       " <p class=\"text\">Drugi paragraf</p>,\n",
       " <p class=\"text\" id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c90a5d",
   "metadata": {},
   "source": [
    "Aby osiągnąć za pomocą find znalezienie paragrafów z klasy text musimy wykorzystać argument _class:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4b8e3d68",
   "metadata": {},
   "source": [
    "text_paragraphs = soup2.find_all('p', class_='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c3dd912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\">Pierwszy paragraf</p>,\n",
       " <p class=\"text\">Drugi paragraf</p>,\n",
       " <p class=\"text\" id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e154734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\" id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ewentualnie\n",
    "soup2.find_all('p', attrs={\"class\": \"text\", \"id\": \"special\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6dd19c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"text\" id=\"special\">Trzeci paragraf</p>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warto pokazać tutaj również wykorzystanie id (attrs)\n",
    "soup2.find_all('p', {\"id\": \"special\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a5cae",
   "metadata": {},
   "source": [
    "# Część 3: Pakiet requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c25f9",
   "metadata": {},
   "source": [
    "Wiedza z poprzednich części będzie teraz wykorzystana w praktyce. Zanim przejdziemy do ćwiczenia zapoznamy się z pakietem requests, który umożliwi nam wysyłanie żądań HTTP. Obsługuje on wszystkie popularne metody HTTP, takie jak GET, POST, PUT, DELETE...\n",
    "Inne pakiety tego typu to np. wbudowane urllib oraz http.client. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93393f9e",
   "metadata": {},
   "source": [
    "Aby korzystać z requests, najpierw trzeba zainstalować pakiet. Możemy to zrobić za pomocą pip (systemu zarządzania pakietami w Pythonie):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a1c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63076652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13651da",
   "metadata": {},
   "source": [
    "POST Request\n",
    "\n",
    "Zapytanie POST służy do wysyłania danych do serwera, na przykład przy przesyłaniu formularza. Niekótre z metod przetestujemy na stronie https://httpbin.org/#/, która umożliwia testowanie zapytań."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7349d4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.32.3\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-673afe8b-075f59ad4dbc87bf3144221a\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"5.173.164.54\", \n",
      "  \"url\": \"https://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "response = requests.post('https://httpbin.org/post', data=payload)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c781b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response # Zwraca kod żądania. Więcej można poczytać na przykład tutaj: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b9fa9d",
   "metadata": {},
   "source": [
    "Krótka interpretacja: \n",
    "\n",
    "args: pusty obiekt, co oznacza, że do żądania POST nie zostały dołączone żadne parametry URL\n",
    "\n",
    "data: jest puste, co wskazuje, że żadne dane nie zostały wysłane w ciele żądania w formacie innym niż formularz\n",
    "\n",
    "files: jest puste - w żądaniu POST nie wysłano żadnych plików\n",
    "\n",
    "form: pokazuje dane, które zostały przesłane za pomocą żądania POST. W tym przypadku są to klucze i wartości podane w metodzie post.\n",
    "\n",
    "headers: zawiera nagłówki przesłane razem z żądaniem. Są one automatycznie dodawane przez pakiet requests lub serwer. Poniżej opis kilku z nich.\n",
    "\n",
    "* Host: nazwa hosta, do którego skierowane jest żądanie\n",
    "* User-Agent: identyfikuje klienta wykonującego żądanie, tutaj python-requests/2.31.0 oznacza, że wykorzystano pakiet requests w Pythonie.\n",
    "\n",
    "origin: pokazuje adres IP, z którego wysłano żądanie.\n",
    "\n",
    "url: adres URL, na który wysłano żądanie POST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c8287",
   "metadata": {},
   "source": [
    "GET Request\n",
    "\n",
    "Zapytanie GET służy do pobierania danych z określonego zasobu, a więc jest ono najbardziej przydatne podczas webscrapingu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebd34185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html>\n",
      "<head>\n",
      "    <title>Example Domain</title>\n",
      "\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "    <style type=\"text/css\">\n",
      "    body {\n",
      "        background-color: #f0f0f2;\n",
      "        margin: 0;\n",
      "        padding: 0;\n",
      "        font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "        \n",
      "    }\n",
      "    div {\n",
      "        width: 600px;\n",
      "        margin: 5em auto;\n",
      "        padding: 2em;\n",
      "        background-color: #fdfdff;\n",
      "        border-radius: 0.5em;\n",
      "        box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "    }\n",
      "    a:link, a:visited {\n",
      "        color: #38488f;\n",
      "        text-decoration: none;\n",
      "    }\n",
      "    @media (max-width: 700px) {\n",
      "        div {\n",
      "            margin: 0 auto;\n",
      "            width: auto;\n",
      "        }\n",
      "    }\n",
      "    </style>    \n",
      "</head>\n",
      "\n",
      "<body>\n",
      "<div>\n",
      "    <h1>Example Domain</h1>\n",
      "    <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>\n",
      "    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://example.com')\n",
    "print(response.text)  # Wyświetla zawartość strony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8e4db49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056cced",
   "metadata": {},
   "source": [
    "A więc możemy pobrać zawartość strony (jej treść HTML) z wykorzystaniem requests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a500483",
   "metadata": {},
   "source": [
    "**Ćwiczenie:**\n",
    "Wyszukiwanie poszczególnych elementów na stronie\n",
    "\n",
    "W tym zadaniu proszę (wykorzystując Beautiful Soup) wypisać treść nagłówków, paragrafaów oraz zlokalizować hiperłącza znajdujące się na stronie https://example.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b7ddeac5-a44d-46ae-9d06-90d31d67fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup2 = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "931d6721-3f18-48dd-bf87-bb516410391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1>Example Domain</h1>]\n",
      "[<p>This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.</p>, <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.iana.org/domains/example']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = soup2.find_all('h1')\n",
    "paragraphs = soup2.find_all('p')\n",
    "hiperLinks = [hiper['href'] for hiper in soup2.find_all('a')]\n",
    "print(headers)\n",
    "print(paragraphs)\n",
    "hiperLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eea9f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu wpisz rozw\n",
    "results = dict(paragraphs=paragraphs, headers=headers, hiperLinks=hiperLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c4b75e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [<p>This domain is for use in illustrative examples in documents. You may use this\n",
       "      domain in literature without prior coordination or asking for permission.</p>,\n",
       "  <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>],\n",
       " 'headers': [<h1>Example Domain</h1>],\n",
       " 'hiperLinks': ['https://www.iana.org/domains/example']}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a330f",
   "metadata": {},
   "source": [
    "Nagłówki\n",
    "\n",
    "Możemy sami definiować nagłówki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ae5a5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"key1\": \"value1\", \n",
      "    \"key2\": \"value2\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate\", \n",
      "    \"Content-Length\": \"23\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"Marcin\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-673b02aa-17f583b90f9ce1aa240b6b0b\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"5.173.164.54\", \n",
      "  \"url\": \"https://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Marcin'}\n",
    "payload = {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "response = requests.post('https://httpbin.org/post', data=payload, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541af7eb",
   "metadata": {},
   "source": [
    "Teraz sami zdefiniowaliśmy nagłówek i widoczne jest to w odpowiedzi. Niekiedy działanie takie może być bardzo przydatne:)\n",
    "\n",
    " \"User-Agent\": \"Marcin\", "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aaa444",
   "metadata": {},
   "source": [
    "Ciasteczka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dd62b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RequestsCookieJar[]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('http://example.com')\n",
    "print(response.cookies)  # Wyświetla ciasteczka z odpowiedzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645afab",
   "metadata": {},
   "source": [
    "# Część 4: FastAPI i requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8723532d",
   "metadata": {},
   "source": [
    "FastAPI to nowoczesny, szybki (wysokowydajny) framework do tworzenia API z Pythonem 3.7+ oparty na standardowych typach Pythona. Jest on używany do tworzenia interfejsów API*\n",
    "\n",
    "*  *https://fastapi.tiangolo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf819b",
   "metadata": {},
   "source": [
    "Aby rozpocząć, musimy zainstalować FastAPI oraz Uvicorn, który służy jako serwer ASGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc395f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install fastapi uvicorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e272c23d",
   "metadata": {},
   "source": [
    "Tworzenie prostego endpointu w FastAPI . Oto podstawowy przykład, w którym endpoint HTTP GET zwraca słownik w formacie JSON."
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb0c2803",
   "metadata": {},
   "source": [
    "# Plik main.py\n",
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "    return {\"Test\": \"API\"}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efa16145",
   "metadata": {},
   "source": [
    "# Polecenie w bashu - main oznacza, że plik main.py zawiera definicję naszej aplikacji i znajduje się w obecnym katalogu\n",
    "# --reload zapewnia restart aplikacji po zmianach w jej kodzie.\n",
    "uvicorn main:app --reload"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e38e3a25",
   "metadata": {},
   "source": [
    "# Podgląd katalogów bazowych oraz konsola po uruchomieniu aplikacji \n",
    "Directory of C:\\Users\\Marcin\\Desktop\\fastapi\n",
    "\n",
    "09.12.2023  16:46    <DIR>          .\n",
    "09.12.2023  16:46    <DIR>          ..\n",
    "09.12.2023  16:45               115 main.py\n",
    "09.12.2023  16:46    <DIR>          __pycache__\n",
    "               1 File(s)            115 bytes\n",
    "               3 Dir(s)  19 312 545 792 bytes free\n",
    "\n",
    "(base) C:\\Users\\Marcin\\Desktop\\fastapi>uvicorn main:app --reload\n",
    "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['C:\\\\Users\\\\Marcin\\\\Desktop\\\\fastapi']\n",
    "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
    "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m15876\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
    "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m8764\u001b[0m]\n",
    "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
    "\u001b[32mINFO\u001b[0m:     Application startup complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c894ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Test\":\"API\"}\n",
      "{'Test': 'API'}\n"
     ]
    }
   ],
   "source": [
    "# Wykonujemy request do naszego API (na przykład możemy wykorzystać PyCharma) - domyślnie pod \n",
    "# http://127.0.0.1:8000 (widoczne powyżej: vicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit))\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:8000/\")\n",
    "response\n",
    "print(response.text)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jako wyjście otrzymujemy {\"Test\": \"API\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd7fb5",
   "metadata": {},
   "source": [
    "# Część 5: Zaawansowany Webscraping (dla zainteresowanych)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b120b1",
   "metadata": {},
   "source": [
    "Strony Dynamiczne:\n",
    "\n",
    "Strony dynamiczne wykorzystują JavaScript do ładowania treści asynchronicznie po załadowaniu głównej struktury strony. Oznacza to, że treści mogą być ładowane i zmieniane bez konieczności przeładowania całej strony."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9de9f",
   "metadata": {},
   "source": [
    "AJAX (Asynchronous JavaScript and XML):\n",
    "\n",
    "AJAX pozwala na wymianę danych z serwerem i aktualizację części strony bez konieczności przeładowania całej strony. Jest to kluczowy element stron dynamicznych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb4950",
   "metadata": {},
   "source": [
    "Uwaga - Beautiful Soup i JavaScript! \n",
    "\n",
    "Beautiful Soup **nie jest** przystosowany do obsługi JavaScript. Potrafi analizować tylko statyczny kod HTML, który otrzymuje.\n",
    "W przypadku stron dynamicznych, które używają JavaScript do ładowania treści, Beautiful Soup nie będzie w stanie uzyskać dostępu do tych dynamicznie generowanych treści.\n",
    "W takich przypadkach lepszym rozwiązaniem jest użycie narzędzi takich jak Selenium, które potrafią obsługiwać JavaScript i dynamiczne treści."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aaaecf",
   "metadata": {},
   "source": [
    "Pakiet Selenium - bardzo często wykorzystywany przy implementacji botów/crawlerów/scraperów, które pracują na stronach dynamicznych. Poniżej kilka cech zgodnie z dokumentacją:\n",
    "\n",
    "* Selenium jest narzędziem automatyzacji przeglądarek, które pozwala na interakcję ze stronami internetowymi tak, jak robiłby to prawdziwy użytkownik.\n",
    "* Selenium może uruchamiać przeglądarkę, wykonywać na niej skrypty JavaScript, kliknąć w elementy strony itp.\n",
    "* Jest to szczególnie przydatne do scrapowania stron, które silnie polegają na JavaScript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec4e7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.mimuw.edu.pl/en/\")\n",
    "# Można teraz dokonywać interakcji ze stroną, np. klikając w przyciski, wypełniając formularze itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911072a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following calendar events:\n",
      "Event 1: Jakub Paliga - PhD thesis defence\n",
      "<div class=\"calendar-event calendar-event-doctorate\" style=\"width:90px;top:27px;left:3px;\" data-id=\"7245\" data-row=\"0\" data-start=\"0\" data-end=\"1\"><div class=\"calendar-event-text\">Jakub Paliga - PhD thesis defence</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">PhD thesis defence</div><table><tr><td class=\"calendar-tooltip-label\">Phd Student</td><td class=\"calendar-tooltip-text\"><a href=\"/en/doctorates/jakub-paliga/\">Jakub Paliga</a></td></tr><tr><td class=\"calendar-tooltip-label\">Thesis</td><td class=\"calendar-tooltip-text\">Equivariant Khovanov Homotopy Types</td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-18 16:00</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-18 18:00</td></tr></table></div></div></div>\n",
      "Event 2: Tomasz Lizurej - PhD thesis defence\n",
      "<div class=\"calendar-event calendar-event-doctorate\" style=\"width:90px;top:27px;left:379px;\" data-id=\"7269\" data-row=\"0\" data-start=\"4\" data-end=\"5\"><div class=\"calendar-event-text\">Tomasz Lizurej - PhD thesis defence</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">PhD thesis defence</div><table><tr><td class=\"calendar-tooltip-label\">Phd Student</td><td class=\"calendar-tooltip-text\"><a href=\"/en/doctorates/tomasz-lizurej/\">Tomasz Lizurej</a></td></tr><tr><td class=\"calendar-tooltip-label\">Thesis</td><td class=\"calendar-tooltip-text\">On Security of Systems Built on Blockchains</td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-22 12:00</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-22 14:00</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=1024\">2180</a></td></tr></table></div></div></div>\n",
      "Event 3: North Atlantic Noncommutative Geometry Seminar\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:91px;left:191px;\" data-id=\"7278\" data-row=\"4\" data-start=\"2\" data-end=\"3\"><div class=\"calendar-event-text\">North Atlantic Noncommutative Geometry Seminar</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/north-atlantic-noncommutative-geometry-seminar/\">North Atlantic Noncommutative Geometry Seminar</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">ALAIN CONNES</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/from-class-field-theory-to-zeta-spectral-triples/\">FROM CLASS FIELD THEORY TO ZETA SPECTRAL TRIPLES</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-20 17:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-20 19:00</td></tr><tr><td class=\"calendar-tooltip-label\">Link</td><td class=\"calendar-tooltip-text\"><a href=\"https://uw-edu-pl.zoom.us/j/95105055663?pwd=TTIvVkxmMndhaHpqMFUrdm8xbzlHdz09\">Zoom</a></td></tr></table></div></div></div>\n",
      "Event 4: Piotr Różański - PhD thesis defence\n",
      "<div class=\"calendar-event calendar-event-doctorate\" style=\"width:90px;top:59px;left:191px;\" data-id=\"7296\" data-row=\"2\" data-start=\"2\" data-end=\"3\"><div class=\"calendar-event-text\">Piotr Różański - PhD thesis defence</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">PhD thesis defence</div><table><tr><td class=\"calendar-tooltip-label\">Phd Student</td><td class=\"calendar-tooltip-text\"><a href=\"/en/doctorates/piotr-rozanski/\">Piotr Różański</a></td></tr><tr><td class=\"calendar-tooltip-label\">Thesis</td><td class=\"calendar-tooltip-text\">Heterogeneous Matching Pursuit Implementation with Continuous Parameter Space Simulation</td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-20 14:30</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-20 17:00</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=1024\">2180</a></td></tr></table></div></div></div>\n",
      "Event 5: Algebra\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:43px;left:285px;\" data-id=\"7307\" data-row=\"1\" data-start=\"3\" data-end=\"4\"><div class=\"calendar-event-text\">Algebra</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-algebra/\">Seminar Algebra</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Paweł Matraś</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk_pl/sprzezenia-blokowych-podalgebr-algebry-macierzy-nad-cialem-i-opis-klas-sprzezonosci-podalgebr-z-tozsamoscia-wielomianowa-x1-y1-x2-y2-xq-yq-0/\"></a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-21 12:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-21 13:45</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=890\">5450</a></td></tr></table></div></div></div>\n",
      "Event 6: Comp. Biol. and Bioinf.\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:27px;left:191px;\" data-id=\"7308\" data-row=\"0\" data-start=\"2\" data-end=\"3\"><div class=\"calendar-event-text\">Comp. Biol. and Bioinf.</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-computational-biology-and-bioinformatics/\">Seminar Computational Biology and Bioinformatics</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Tomasz W. Turowski</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/model-of-immobilized-rna-polymerase/\">Model of immobilized RNA polymerase</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-20 10:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-20 11:45</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=712\">3250</a></td></tr></table></div></div></div>\n",
      "Event 7: Sem. of Probability Group\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:59px;left:285px;\" data-id=\"7309\" data-row=\"2\" data-start=\"3\" data-end=\"4\"><div class=\"calendar-event-text\">Sem. of Probability Group</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-of-probability-group/\">Seminar of Probability Group</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Dominik Kutek</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/bregman-variation-of-semimartingales/\">Bregman variation of semimartingales</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-21 12:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-21 13:45</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=705\">3160</a></td></tr></table></div></div></div>\n",
      "Event 8: Sem. Num. Analysis\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:27px;left:285px;\" data-id=\"7310\" data-row=\"0\" data-start=\"3\" data-end=\"4\"><div class=\"calendar-event-text\">Sem. Num. Analysis</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-of-numerical-analysis-group/\">Seminar of Numerical Analysis Group</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Leszek Plaskota</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/my-subjective-view-of-numerical-algorithms/\">My subjective view of numerical algorithms</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-21 10:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-21 12:00</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=756\">4070</a></td></tr></table></div></div></div>\n",
      "Event 9: Algorithms\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:43px;left:379px;\" data-id=\"7312\" data-row=\"1\" data-start=\"4\" data-end=\"5\"><div class=\"calendar-event-text\">Algorithms</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-algorithms/\">Seminar Algorithms</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Kunal Dutta</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/a-euclidean-embedding-for-computing-persistent-homology-with-gaussian-kernels/\">A Euclidean Embedding for Computing Persistent Homology with Gaussian Kernels</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-22 14:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-22 15:45</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=759\">5060</a></td></tr></table></div></div></div>\n",
      "Event 10: Biomath. & Game Theory\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:43px;left:191px;\" data-id=\"7315\" data-row=\"1\" data-start=\"2\" data-end=\"3\"><div class=\"calendar-event-text\">Biomath. &amp; Game Theory</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-of-biomathematics-and-game-theory-group/\">Seminar of Biomathematics and Game Theory Group</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Elżbieta Pliś</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/diversity-and-evolution-of-the-economic-system/\">Diversity and evolution of the economic system</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-20 14:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-20 15:45</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=760\">5070</a></td></tr></table></div></div></div>\n",
      "Event 11: Topology and Set Theory\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:75px;left:191px;\" data-id=\"7316\" data-row=\"3\" data-start=\"2\" data-end=\"3\"><div class=\"calendar-event-text\">Topology and Set Theory</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/topology-and-set-theory-seminar/\">Topology and Set Theory Seminar</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">Tomasz Weiss</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk/some-remarks-on-subsets-of-r-defined-in-terms-of-the-translations-of-sets-which-belong-to-the-four-most-common-sigma-ideals-in-r/\">Some remarks on subsets of R defined in terms of the translations of sets which belong to the four most common sigma ideals in R</a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-20 16:15</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-20 18:00</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=758\">5050</a></td></tr></table></div></div></div>\n",
      "Event 12: Intelligent Systems\n",
      "<div class=\"calendar-event calendar-event-seminar\" style=\"width:90px;top:59px;left:379px;\" data-id=\"7317\" data-row=\"2\" data-start=\"4\" data-end=\"5\"><div class=\"calendar-event-text\">Intelligent Systems</div><div class=\"calendar-tooltip-outer calendar-tooltip-outer-left\"><div class=\"calendar-tooltip\"><div class=\"calendar-tooltip-header\">Talk on seminar</div><table><tr><td class=\"calendar-tooltip-label\">Semianar</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/seminar-intelligent-systems/\">Seminar Intelligent Systems</a></td></tr><tr><td class=\"calendar-tooltip-label\">Speaker(s)</td><td class=\"calendar-tooltip-text\">dr Wojciech Oronowicz-Jaśkowiak</td></tr><tr><td class=\"calendar-tooltip-label\">Title</td><td class=\"calendar-tooltip-text\"><a href=\"/en/seminars/talk_pl/propozycja-integracyjnego-obiektowo-klasowego-klasyfikatora-tresci-pornograficznych-z-udzialem-maloletniego/\"></a></td></tr><tr><td class=\"calendar-tooltip-label\">From</td><td class=\"calendar-tooltip-text\">2024-11-22 16:00</td></tr><tr><td class=\"calendar-tooltip-label\">To</td><td class=\"calendar-tooltip-text\">2024-11-22 17:30</td></tr><tr><td class=\"calendar-tooltip-label\">Room</td><td class=\"calendar-tooltip-text\"><a href=\"/en/rooms/?room=755\">4060</a></td></tr><tr><td class=\"calendar-tooltip-label\">Link</td><td class=\"calendar-tooltip-text\"><a href=\"https://meet.google.com/jbj-tdsr-aop\">Google Meet</a></td></tr></table></div></div></div>\n"
     ]
    }
   ],
   "source": [
    "# Źródło strony\n",
    "#print(driver.page_source)\n",
    "\n",
    "calendar_events = driver.find_elements(By.CLASS_NAME, 'calendar-event')\n",
    "#print(calendar_events)\n",
    "if calendar_events:\n",
    "    print(\"Found the following calendar events:\")\n",
    "    for index, event in enumerate(calendar_events, start=1):\n",
    "        full = event.get_attribute(\"outerHTML\")\n",
    "        print(f\"Event {index}: {event.text}\")\n",
    "        print(full)\n",
    "else:\n",
    "    print(\"No calendar events found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d3aba7",
   "metadata": {},
   "source": [
    "CAPTCHA i Bot Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febe5e68",
   "metadata": {},
   "source": [
    "* UWAGA: Zawsze przestrzegaj zasad i warunków korzystania ze strony!\n",
    "\n",
    "* Scrapowanie możemy rozpocząć tylko wtedy, gdy mamy zgodę właściciela treści, administratora serwera, strony lub strona zezwala na automatyzację zapytań.\n",
    "\n",
    "* Strony internetowe często używają CAPTCHA i mechanizmów wykrywania botów, aby zapobiec automatycznemu scrapowaniu i innym formom nadużyć.\n",
    "\n",
    "* Automatyczne obejście CAPTCHA i mechanizmów wykrywania botów może naruszać warunki korzystania z serwisu i być nieetyczne.\n",
    "\n",
    "* Do dużych projektów programistycznych można wykorzystać również pakiet scrapy, który z wykorzystaniem scrapy.Spider pozwala na budowę zaawansowanych scraperów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
